{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, glob\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "# Load Standard Scaler (same as z-normalization) for normalization of whole image\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call subjects from desired institution(this code only works for one institutions) for testing\n",
    "seg_dir = 'segmentation images directory'\n",
    "baseline_dir = 'baseline images(t1,t1ce,t2,flair,adc)'\n",
    "\n",
    "segm_dir = sorted(glob.glob(os.path.join(seg_dir, \"*_seg*.nii.gz\"))) \n",
    "\n",
    "flair_dir = sorted(glob.glob(os.path.join(baseline_dir, \"*_flair*.nii.gz\"))) \n",
    "t1_dir = sorted(glob.glob(os.path.join(baseline_dir, \"*_t1_*.nii.gz\"))) \n",
    "t1ce_dir = sorted(glob.glob(os.path.join(baseline_dir, \"*_t1ce*.nii.gz\"))) \n",
    "t2_dir = sorted(glob.glob(os.path.join(baseline_dir, \"*_t2*.nii.gz\"))) \n",
    "adc_dir = sorted(glob.glob(os.path.join(baseline_dir, \"*_adc*.nii.gz\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load nifti files into numpy array\n",
    "def LoadingImage(dir):\n",
    "    \n",
    "    nifti_image = nib.load(dir)\n",
    "    image = np.asarray(nifti_image.dataobj)\n",
    "    header = nifti_image.header\n",
    "    imgaffine = nifti_image.affine\n",
    "    \n",
    "    return image, header, imgaffine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separately collects unique subject name from files name\n",
    "def getFilename(full_dir):\n",
    "    _,filename = full_dir.split('\\\\')\n",
    "    print(filename)\n",
    "    subject,_,_,_,_= filename.split('_')\n",
    "    return str(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple 3D CNN network (same as training network)\n",
    "class Simple3DCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Simple3DCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(5, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 5 * 5 * 5, 128)  # 128 is an arbitrary choice, feel free to change\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))  # apply conv1, then ReLU\n",
    "        x = torch.relu(self.conv2(x))  # apply conv2, then ReLU\n",
    "        x = x.view(x.size(0), -1)  # flatten the tensor\n",
    "        x = torch.relu(self.fc1(x))  # apply first fully connected layer, then ReLU\n",
    "        x = self.dropout(x)  # apply dropout\n",
    "        x = self.fc2(x)  # apply second fully connected layer\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contunuous case\n",
    "# Load the model\n",
    "model = Simple3DCNN(num_classes=2)\n",
    "model.load_state_dict(torch.load('Load the model weights that you trained'))\n",
    "model.eval()\n",
    "\n",
    "# iterate each subjects\n",
    "# Assuming the file names in each directory match up\n",
    "for i in range(len(segm_dir)):\n",
    "    # Seg (240, 240, 155)\n",
    "    seg_img, seg_hdr, seg_imgaffine = LoadingImage(segm_dir[i])\n",
    "\n",
    "    # Load your 5-channel 3D image with size (240,240,155,5)\n",
    "    img_dirs = [flair_dir[i], t1_dir[i], t1ce_dir[i], t2_dir[i], adc_dir[i]]\n",
    "    \n",
    "    # Now the image is in (C, H, W, D) format\n",
    "    img = np.stack([nib.load(dir).get_fdata() for dir in img_dirs], axis=0)  \n",
    "    \n",
    "    # Normalize each channel separately\n",
    "    img = np.stack([scaler.fit_transform(channel.reshape(-1, 1)).reshape(channel.shape) for channel in img], axis=0)\n",
    "\n",
    "    # Find the voxels with a label of 2\n",
    "    voxels = np.where(seg_img == 2)\n",
    "\n",
    "    # Create an array to hold the output values\n",
    "    output = np.zeros_like(seg_img, dtype=float)\n",
    "\n",
    "    # filename\n",
    "    filename = getFilename(segm_dir[i])\n",
    "\n",
    "    # Iterate over the voxels\n",
    "    for voxel_index in range(len(voxels[0])):\n",
    "        x, y, z = voxels[0][voxel_index], voxels[1][voxel_index], voxels[2][voxel_index]\n",
    "        # Make sure the patch is completely inside the image\n",
    "        if x-2 >= 0 and x+2 < 240 and y-2 >= 0 and y+2 < 240 and z-2 >= 0 and z+2 < 155:\n",
    "            # Extract the patch around the voxel\n",
    "            patch = img[:, x-2:x+3, y-2:y+3, z-2:z+3]\n",
    "            # Preprocess the patch if needed, for example if your model expects a certain shape\n",
    "            patch = np.expand_dims(patch, axis=0)  # Now the patch is in (N, C, H, W, D) format\n",
    "            patch = torch.from_numpy(patch).float()\n",
    "            # Get the binary classification output from the model\n",
    "            with torch.no_grad():\n",
    "                outputs = model(patch)\n",
    "                probabilities = torch.sigmoid(outputs).data\n",
    "            # Put the output value back into the original voxel\n",
    "            output[x, y, z] = probabilities[0][1].item()\n",
    "\n",
    "    # Save the output\n",
    "    nifti_img = nib.Nifti1Image(output, seg_imgaffine, seg_hdr)\n",
    "    nib.save(nifti_img, 'save the result probaility map back into original space')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
